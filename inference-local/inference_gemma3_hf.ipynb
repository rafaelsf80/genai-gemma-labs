{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI6jQZyLQouk"
      },
      "source": [
        "# Inferencia Gemma 3-4B con Function calling y multimodal\n",
        "\n",
        "Function calling with Duckduckgo search and multimodal capabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPG9Tt-xRXnN"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpQ4yzBIHGbH"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install accelerate\n",
        "!pip install duckduckgo-search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUSjniskUsyc"
      },
      "source": [
        "## Carga modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us9dCp87GgVN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, Gemma3ForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0p-2edQBR4af"
      },
      "outputs": [],
      "source": [
        "model_id = \"google/gemma-3-4b-it\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LISsLCCiGUVm"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83f33e2bb29544ddb2dfd8da62c9ca8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "model = Gemma3ForConditionalGeneration.from_pretrained(\n",
        "    model_id, device_map=\"auto\", token = hf_token\n",
        ").eval()\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnzOHRPtoQut"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i47OYekFdM4V"
      },
      "source": [
        "## Function Calling con Gemma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgU2fCoycyhu"
      },
      "outputs": [],
      "source": [
        "from duckduckgo_search import DDGS\n",
        "\n",
        "def search(query:str):\n",
        "  \"\"\"\n",
        "  search results to the user query\n",
        "\n",
        "  Args:\n",
        "      query: user prompt to fetch search results\n",
        "  \"\"\"\n",
        "  req = DDGS()\n",
        "  response = req.text(query,max_results=4)\n",
        "  context = \"\"\n",
        "  for result in response:\n",
        "    context += result['body']\n",
        "  return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQiUJlCBdb8Y"
      },
      "outputs": [],
      "source": [
        "tools = [search]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3z_9TbvufF3"
      },
      "outputs": [],
      "source": [
        "query = \"which teams played Cricket ICC Champions Trophy 2025 finals and who won?\" # this is a realtime query, this event occured on March 9th 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHQrvzvRR7n8"
      },
      "source": [
        "## Definir prompt para function calling\n",
        "\n",
        "Function Calling follows these steps:\n",
        "\n",
        "- Your application sends a prompt to the LLM along with function definitions\n",
        "- The LLM analyzes the prompt and decides whether to respond directly or use defined functions\n",
        "- If using functions, the LLM generates structured arguments for the function call\n",
        "- Your application receives the function call details and executes the actual function\n",
        "- The function results are sent back to the LLM\n",
        "- The LLM provides a final response incorporating the function results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4LiCaOodjyn"
      },
      "outputs": [],
      "source": [
        "conversation = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": [{\"type\": \"text\", \"text\": \"\"\"\n",
        "        You are an expert search assistant. Use `search` to get the most accurate details.\n",
        "        At each turn, if you decide to invoke any of the function(s), it should be wrapped with ```tool_code```. The python methods described below are imported and available,\n",
        "        you can only use defined methods. The generated code should be readable and efficient. The response to a method will be wrapped in ```tool_output``` use it to call more tools or generate a helpful, friendly response.\n",
        "        When using a ```tool_call``` think step by step why and how it should be used.\n",
        "\n",
        "        The following Python methods are available:\n",
        "        \\`\\`\\`python\n",
        "        def search(query:str):\n",
        "          \"\n",
        "          search results to the user query\n",
        "\n",
        "          Args:\n",
        "             query: user prompt to fetch search results\n",
        "          \"\n",
        "        \\`\\`\\`\n",
        "\n",
        "        User: \\{user_message\\}\n",
        "        \"\"\"}]\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"text\", \"text\": query}\n",
        "        ]\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nh51Dr6Xde9r"
      },
      "outputs": [],
      "source": [
        "inputs = processor.apply_chat_template(\n",
        "            conversation,\n",
        "            tools=tools,\n",
        "            add_generation_prompt=True,\n",
        "            return_dict=True,\n",
        "            tokenize=True,\n",
        "            return_tensors=\"pt\",\n",
        ").to(model.device, dtype=torch.bfloat16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNO25997ebXH"
      },
      "outputs": [],
      "source": [
        "outputs = model.generate(**inputs, max_new_tokens=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN32I1J2ltjN"
      },
      "outputs": [],
      "source": [
        "output = processor.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moOkqbxAo0TT"
      },
      "outputs": [],
      "source": [
        "response = output.split(\"model\")[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGF5oJyntu7C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "```tool_code\n",
            "search(query=\"Which teams played in the Cricket ICC Champions Trophy 2025 final and who won?\")\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pldp3z7USS5P"
      },
      "source": [
        "## Ejecutar la funciÃ³n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni57IK_OpIya"
      },
      "outputs": [],
      "source": [
        "def extract_tool_call(text):\n",
        "    import io\n",
        "    from contextlib import redirect_stdout\n",
        "\n",
        "    pattern = r\"```tool_code\\s*(.*?)\\s*```\"\n",
        "    match = re.search(pattern, text, re.DOTALL)\n",
        "    if match:\n",
        "        code = match.group(1).strip()\n",
        "        # Capture stdout in a string buffer\n",
        "        f = io.StringIO()\n",
        "        with redirect_stdout(f):\n",
        "            result = eval(code)\n",
        "        output = f.getvalue()\n",
        "        r = result if output == '' else output\n",
        "        return f'```tool_output\\n{r}\\n```'''\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRYVbLKdosaN"
      },
      "outputs": [],
      "source": [
        "keyword = extract_tool_call(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eznPlrIBpddw"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"```tool_output\\nThe ninth edition of the Champions Trophy 2025 saw India being crowned as the winners on 9th March 2025 after they overcame New Zealand in the final. Several exceptional performers lit up the tournament with the bat and ball. The best of them made it to the Team of the Tournament. Here's what the side looks like: 1. Rachin Ravindra (New Zealand)The 2025 ICC Champions Trophy was the ninth edition of the ICC Champions Trophy, a quadrennial ODI cricket tournament organised by the International Cricket Council (ICC). In November 2021 as part of the 2024-2031 ICC men's hosts cycle, the ICC announced that the 2025 Champions Trophy would be played in Pakistan. [4]On 19 December 2024, following an agreement between Board of Control for ...Official ICC Champions Trophy, 2025 Cricket website - live matches, scores, news, highlights, commentary, rankings, videos and fixtures from the International Cricket Council. ... 2025. ICC announces Champions Trophy 2025 Team of the Tournament ... Kohli stars as India march into final | Champions Trophy 2025. 4 March, 2025. ICC Champions ...In a thrilling ICC Champions Trophy final at the Dubai International Cricket Stadium on March 9, 2025, India emerged victorious over New Zealand, clinching the title in a closely contested match ...\\n```\""
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keyword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ek9wlj3xuOnc"
      },
      "outputs": [],
      "source": [
        "prompt = [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"text\", \"text\": f\"Results from the search:{keyword} User_query : {query}\"}\n",
        "        ]\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QB331y_TvN7K"
      },
      "outputs": [],
      "source": [
        "final_prompt = processor.apply_chat_template(\n",
        "            prompt,\n",
        "            tools=tools,\n",
        "            add_generation_prompt=True,\n",
        "            return_dict=True,\n",
        "            tokenize=True,\n",
        "            return_tensors=\"pt\",\n",
        ").to(model.device, dtype=torch.bfloat16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcjE05aSvHEI"
      },
      "outputs": [],
      "source": [
        "response = model.generate(**final_prompt, max_new_tokens=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBcgbJjEvlW4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user\n",
            "Results from the search:```tool_output\n",
            "The ninth edition of the Champions Trophy 2025 saw India being crowned as the winners on 9th March 2025 after they overcame New Zealand in the final. Several exceptional performers lit up the tournament with the bat and ball. The best of them made it to the Team of the Tournament. Here's what the side looks like: 1. Rachin Ravindra (New Zealand)The 2025 ICC Champions Trophy was the ninth edition of the ICC Champions Trophy, a quadrennial ODI cricket tournament organised by the International Cricket Council (ICC). In November 2021 as part of the 2024-2031 ICC men's hosts cycle, the ICC announced that the 2025 Champions Trophy would be played in Pakistan. [4]On 19 December 2024, following an agreement between Board of Control for ...Official ICC Champions Trophy, 2025 Cricket website - live matches, scores, news, highlights, commentary, rankings, videos and fixtures from the International Cricket Council. ... 2025. ICC announces Champions Trophy 2025 Team of the Tournament ... Kohli stars as India march into final | Champions Trophy 2025. 4 March, 2025. ICC Champions ...In a thrilling ICC Champions Trophy final at the Dubai International Cricket Stadium on March 9, 2025, India emerged victorious over New Zealand, clinching the title in a closely contested match ...\n",
            "``` User_query : which teams played Cricket ICC Champions Trophy 2025 finals and who won?\n",
            "model\n",
            "According to the search results:\n",
            "\n",
            "*   **Teams:** India and New Zealand\n",
            "*   **Winner:** India won the final on March 9, 2025.\n"
          ]
        }
      ],
      "source": [
        "print(processor.decode(response[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multimedia. Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "from IPython.display import Markdown, HTML\n",
        "\n",
        "\n",
        "def resize_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    target_width, target_height = 640, 640\n",
        "    # Calculate the target size (maximum width and height).\n",
        "    if target_width and target_height:\n",
        "        max_size = (target_width, target_height)\n",
        "    elif target_width:\n",
        "        max_size = (target_width, img.height)\n",
        "    elif target_height:\n",
        "        max_size = (img.width, target_height)\n",
        "\n",
        "    img.thumbnail(max_size)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def get_model_response(img: Image, prompt: str, model, processor):\n",
        "    # Prepare the messages for the model.\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant. Reply only with the answer to the question asked, and avoid using additional text in your response like 'here's the answer'.\"}]\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"image\", \"image\": img},\n",
        "                {\"type\": \"text\", \"text\": prompt}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Tokenize inputs and prepare for the model.\n",
        "    inputs = processor.apply_chat_template(\n",
        "        messages, add_generation_prompt=True, tokenize=True,\n",
        "        return_dict=True, return_tensors=\"pt\"\n",
        "    ).to(model.device, dtype=torch.bfloat16)\n",
        "\n",
        "    input_len = inputs[\"input_ids\"].shape[-1]\n",
        "\n",
        "    # Generate response from the model.\n",
        "    with torch.inference_mode():\n",
        "        generation = model.generate(**inputs, max_new_tokens=100, do_sample=False)\n",
        "        generation = generation[0][input_len:]\n",
        "\n",
        "    # Decode the response.\n",
        "    response = processor.decode(generation, skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "\n",
        "def extract_frames(video_path, num_frames):\n",
        "    \"\"\"\n",
        "    The function is adapted from:\n",
        "    https://github.com/merveenoyan/smol-vision/blob/main/Gemma_3_for_Video_Understanding.ipynb\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video file.\")\n",
        "        return []\n",
        "\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Calculate the step size to evenly distribute frames across the video.\n",
        "    step = total_frames // num_frames\n",
        "    frames = []\n",
        "\n",
        "    for i in range(num_frames):\n",
        "        frame_idx = i * step\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        timestamp = round(frame_idx / fps, 2)\n",
        "        frames.append((img, timestamp))\n",
        "\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "\n",
        "def show_video(video_path, video_width = 600):\n",
        "  video_file = open(video_path, \"r+b\").read()\n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  video_html = f\"\"\"\"\"\"\n",
        "  return HTML(video_html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference on images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/NSTiwari/Inference-Gemma-3/main/assets/image_1.png -O /content/image_1.png\n",
        "!wget https://raw.githubusercontent.com/NSTiwari/Inference-Gemma-3/main/assets/image_2.png -O /content/image_2.png\n",
        "!wget https://raw.githubusercontent.com/NSTiwari/Inference-Gemma-3/main/assets/image_3.png -O /content/image_3.png\n",
        "!wget https://raw.githubusercontent.com/NSTiwari/Inference-Gemma-3/main/assets/image_4.png -O /content/image_4.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_file = 'image_1.png' \n",
        "prompt = \"Describe the image.\" \n",
        "\n",
        "img = resize_image(image_file)\n",
        "display(img)\n",
        "response = get_model_response(img, prompt, model, processor)\n",
        "display(Markdown(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_file = 'image_2.png' \n",
        "prompt = \"Identify the famous landmark and location.\" \n",
        "\n",
        "img = resize_image(image_file)\n",
        "display(img)\n",
        "response = get_model_response(img, prompt, model, processor)\n",
        "display(Markdown(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_file = 'image_3.png' \n",
        "prompt = \"que es este dibujo ? \" \n",
        "\n",
        "img = resize_image(image_file)\n",
        "display(img)\n",
        "response = get_model_response(img, prompt, model, processor)\n",
        "display(Markdown(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mathematical reasoning\n",
        "\n",
        "from PIL import Image\n",
        "from IPython.display import Markdown\n",
        "\n",
        "image_file = 'image_4.png' \n",
        "prompt = \"What is the value of x?\" \n",
        "\n",
        "img = resize_image(image_file)\n",
        "display(img)\n",
        "response = get_model_response(img, prompt, model, processor)\n",
        "display(Markdown(response))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[Gemma_3]Function_Calling_with_HF.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
